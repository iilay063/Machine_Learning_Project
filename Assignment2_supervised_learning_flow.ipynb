{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec202ada",
   "metadata": {},
   "source": [
    "# Assignment2 - Supervised Learning flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06a2810",
   "metadata": {},
   "source": [
    "# Part 1(a) Student details:\n",
    "* Please write the First-Name, First letter of Last-Name and last 4 digits of the i.d. for each student. "
   ]
  },
  {
   "cell_type": "code",
   "id": "ca16486b",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# stundent details example: John S. 9812\n",
    "#                       student details 1: Ilay W. 0725\n",
    "# (if exists)           student details 2: Aharoni C. 1047\n",
    "# (if exists)           student details 3: Adir B.\n",
    "# (if exists&premitted) student details 4: "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "abb64166-b32e-4b86-a7ee-84106c8b3a92",
   "metadata": {},
   "source": [
    "## Part 1(b) - Chat-GPT/other AI-agent/other assistance used:\n",
    "* If you changed the prompt until you got a satisfying answer, please add all versions\n",
    "* don't delete \"pre\" tags, so new-line is supported\n",
    "* double click the following markdown cell to change\n",
    "* press shift+enter to view\n",
    "* Add information:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea93f0d3-7aa1-4a95-b084-395f5f7c6c0c",
   "metadata": {},
   "source": [
    "#### Add information in this Markdown cell (double click to change, shift-enter to view)\n",
    "<pre>   \n",
    "AI agent name:\n",
    "Goal:\n",
    "Propmpt1:\n",
    "    \n",
    "Propmpt2:\n",
    "    \n",
    "Propmpt3: \n",
    "\n",
    "\n",
    "AI agent name 2:\n",
    "Goal:\n",
    "Propmpt1:\n",
    "    \n",
    "Propmpt2:\n",
    "    \n",
    "Propmpt3: \n",
    "\n",
    "Other assistanse:    \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4fbaab-e5a5-40ed-be0f-9a2cb7931a4b",
   "metadata": {},
   "source": [
    "## Part 1(c) - Learning Problem and dataset explaination.\n",
    "* Please explain in one paragraph\n",
    "* don't delete \"pre\" tags, so new-line is supported\n",
    "* double click the following markdown cell to change\n",
    "* press shift+enter to view\n",
    "* Add explaining text:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8565df-2778-4b89-83bd-6b227063789f",
   "metadata": {},
   "source": [
    "#### Add information in this Markdown cell (double click to change, shift-enter to view)\n",
    "<pre>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df67c2ee-87c8-499c-a04f-1853c332f51d",
   "metadata": {},
   "source": [
    "## Part 2 - Initial Preparations \n",
    "You could add as many code cells as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b3454-b568-4614-8017-f15b3c59fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b47fe56-d611-4b28-be92-673db4d56400",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('titanic_train.csv')\n",
    "test_df = pd.read_csv('titanic_test.csv')\n",
    "\n",
    "print('First 5 training rows:')\n",
    "print(train_df.head())\n",
    "print('\\nFirst 5 test rows:')\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e27610-b640-4db0-80c9-789b5f5fae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Survival counts by passenger class\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=train_df, x='Pclass', hue='Survived')\n",
    "plt.title('Survival count by Passenger Class')\n",
    "plt.savefig('eda_pclass.png')\n",
    "plt.close()\n",
    "\n",
    "# Age distribution for survived vs. not survived passengers\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(data=train_df, x='Age', hue='Survived', kde=True)\n",
    "plt.title('Age distribution by survival')\n",
    "plt.savefig('eda_age.png')\n",
    "plt.close()\n",
    "\n",
    "# Correlation heatmap between the numeric features\n",
    "plt.figure(figsize=(6, 4))\n",
    "cor = train_df.drop('Survived', axis=1).corr()\n",
    "sns.heatmap(cor, annot=True, cmap='coolwarm')\n",
    "plt.title('Feature correlation')\n",
    "plt.savefig('eda_corr.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb36672a",
   "metadata": {},
   "source": [
    "## Part 3 - Experiments\n",
    "You could add as many code cells as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937b653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('Survived', axis=1)\n",
    "y_train = train_df['Survived']\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'clf': [LogisticRegression(max_iter=1000)],\n",
    "        'clf__C': [0.1, 1.0, 10.0]\n",
    "    },\n",
    "    {\n",
    "        'clf': [RandomForestClassifier(random_state=42)],\n",
    "        'clf__n_estimators': [50, 100],\n",
    "        'clf__max_depth': [5, 10, None]\n",
    "    }\n",
    "]\n",
    "\n",
    "scorer = make_scorer(f1_score)\n",
    "\n",
    "# Pipeline contains a standard scaler followed by the classifier\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression())  # replaced by grid search\n",
    "])\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=scorer,\n",
    "    n_jobs=-1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "print('\\nRunning grid search (this may take a moment)...')\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "print('\\nGrid search results (mean test score):')\n",
    "print(results[['params', 'mean_test_score', 'std_test_score']])\n",
    "\n",
    "print('\\nBest parameters:', grid.best_params_)\n",
    "best_model = grid.best_estimator_"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b7098585"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "097afb02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1fa9ec73"
  },
  {
   "cell_type": "markdown",
   "id": "67d97f11",
   "metadata": {},
   "source": [
    "## Part 4 - Training \n",
    "Use the best combination of feature engineering, model (algorithm and hyperparameters) from the experiment part (part 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93713ead",
   "metadata": {},
   "outputs": [],
   "source": "best_model.fit(X_train, y_train)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc460d",
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064ad0a0",
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "markdown",
   "id": "259ab902",
   "metadata": {},
   "source": [
    "## Part 5 - Apply on test and show model performance estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9971aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop('Survived', axis=1)\n",
    "y_test = test_df['Survived']\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "print('\\nTest F1 score:', test_f1)\n",
    "\n",
    "print('\\nFirst 5 predictions:')\n",
    "print(pd.DataFrame({'Actual': y_test[:5].values,\n",
    "                    'Predicted': y_pred[:5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d8aa96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
